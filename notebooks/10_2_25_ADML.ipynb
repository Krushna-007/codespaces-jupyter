{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = [\n",
    "    \"The design of the car's engine is based on principles of thermodynamics.\",\n",
    "    \"Quantum computing has the potential to revolutionize engineering fields.\",\n",
    "    \"In mechanical engineering, fluid dynamics plays a crucial role in design.\",\n",
    "    \"Electrical engineers are increasingly utilizing machine learning algorithms.\",\n",
    "    \"Computer engineering involves hardware and software systems integration.\"\n",
    "]\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation)).lower()\n",
    "    tokens = [word for word in text.split()if word not in stop_words]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [preprocess_text(doc) for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer =TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Singular values:  [1.08049356 1.01836085]\n",
      "\n",
      "LSI components (topics):\n",
      " [[ 5.84651297e-16  1.50700413e-01  1.50700413e-01  1.70543120e-01\n",
      "   1.91528533e-01  2.19096677e-01  2.98349964e-01  2.19096677e-01\n",
      "   5.04083961e-16  1.50700413e-01  3.89215204e-01  5.04083961e-16\n",
      "   1.91528533e-01  2.19096677e-01  1.70543120e-01  5.04083961e-16\n",
      "   1.70543120e-01  1.70543120e-01  5.04083961e-16  5.04083961e-16\n",
      "   2.19096677e-01  2.19096677e-01  1.91528533e-01  1.50700413e-01\n",
      "   1.91528533e-01  1.91528533e-01  2.19096677e-01  1.70543120e-01\n",
      "   1.70543120e-01  1.50700413e-01  5.04083961e-16]\n",
      " [-1.60225811e-16  2.94627183e-01  2.94627183e-01 -1.80839137e-01\n",
      "  -1.91142616e-01  9.47890452e-02  3.14178561e-01  9.47890452e-02\n",
      "   3.83766124e-17  2.94627183e-01 -1.85639187e-01  3.83766124e-17\n",
      "  -1.91142616e-01  9.47890452e-02 -1.80839137e-01  3.83766124e-17\n",
      "  -1.80839137e-01 -1.80839137e-01  3.83765775e-17  3.83765775e-17\n",
      "   9.47890452e-02  9.47890452e-02 -1.91142616e-01  2.94627183e-01\n",
      "  -1.91142616e-01 -1.91142616e-01  9.47890452e-02 -1.80839137e-01\n",
      "  -1.80839137e-01  2.94627183e-01  3.83765775e-17]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "lsi = TruncatedSVD(n_components = 2,n_iter = 100, random_state = 42)\n",
    "lsi_matrix = lsi.fit_transform(X)\n",
    "\n",
    "print(\"Singular values: \",lsi.singular_values_)\n",
    "print(\"\\nLSI components (topics):\\n\", lsi.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "\n",
      " utilizing\n",
      " machine\n",
      " learning\n",
      " engineers\n",
      " electrical\n",
      " increasingly\n",
      " algorithms\n",
      " principles\n",
      " based\n",
      " thermodynamics\n",
      " cars\n",
      " engine\n",
      " computer\n",
      " systems\n",
      " hardware\n",
      " integration\n",
      " involves\n",
      " software\n",
      " fields\n",
      " computing\n",
      " revolutionize\n",
      " potential\n",
      " quantum\n",
      " role\n",
      " mechanical\n",
      "Topic 1:\n",
      "\n",
      " computing\n",
      " revolutionize\n",
      " quantum\n",
      " potential\n",
      " fields\n",
      " engineering\n",
      " systems\n",
      " software\n",
      " computer\n",
      " involves\n",
      " integration\n",
      " hardware\n",
      " algorithms\n",
      " machine\n",
      " learning\n",
      " utilizing\n",
      " engineers\n",
      " electrical\n",
      " increasingly\n",
      " fluid\n",
      " mechanical\n",
      " plays\n",
      " dynamics\n",
      " crucial\n",
      " role\n"
     ]
    }
   ],
   "source": [
    "terms = vectorizer.get_feature_names_out()\n",
    "n_top_words = 5\n",
    "for topic_idx, topic in enumerate(lsi.components_):\n",
    "    print(f\"Topic {topic_idx}:\\n\")\n",
    "    top_terms_idx = topic.argsort()[:-n_top_words -1:1]\n",
    "    for i in top_terms_idx:\n",
    "        print(f\" {terms[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
