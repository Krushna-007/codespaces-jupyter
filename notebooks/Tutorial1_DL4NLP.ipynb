{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "import random\n",
    "import math\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_ngrams(text, n):\n",
    "    padded_text = '#' * (n-1) + text\n",
    "    ngrams = []\n",
    "    for i in range(len(padded_text) - n + 1):\n",
    "        ngram = tuple(padded_text[i:i+n])\n",
    "        ngrams.append(ngram)\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character-Level Bigrams: [('#', '#', 'J'), ('#', 'J', 'a'), ('J', 'a', 'i'), ('a', 'i', ' '), ('i', ' ', 'H'), (' ', 'H', 'i'), ('H', 'i', 'n'), ('i', 'n', 'd')]\n"
     ]
    }
   ],
   "source": [
    "text = \"Jai Hind\"\n",
    "bigrams = generate_ngrams(text, 3)\n",
    "print(\"Character-Level Bigrams:\", bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ngram_model(corpus, n):\n",
    "    \"\"\"\n",
    "    Build an n-gram language model from the corpus.\n",
    "\n",
    "    Parameters:\n",
    "    corpus (str): Text corpus for building the model\n",
    "    n (int): Size of the n-grams\n",
    "\n",
    "    Returns:\n",
    "    dict: A probability distribution for each context\n",
    "    \"\"\"\n",
    "    # Initialize the model\n",
    "    model = defaultdict(Counter)\n",
    "\n",
    "    # Generate n-grams\n",
    "    ngrams = generate_ngrams(corpus, n)\n",
    "\n",
    "    # Build the model\n",
    "    for ngram in ngrams:\n",
    "        context = ngram[:-1]  # all but the last character\n",
    "        char = ngram[-1]      # the last character\n",
    "        model[context][char] += 1\n",
    "\n",
    "    # Convert counts to probabilities\n",
    "    for context in model:\n",
    "        total_count = sum(model[context].values())\n",
    "        for char in model[context]:\n",
    "            model[context][char] = model[context][char] / total_count\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_smoothing(model, vocabulary_size, alpha=1.0):\n",
    "    \"\"\"\n",
    "    Apply smoothing to an n-gram model.\n",
    "\n",
    "    Parameters:\n",
    "    model (defaultdict): N-gram model.\n",
    "    vocabulary_size (int): Total number of unique characters in the vocabulary.\n",
    "    alpha (float): Smoothing parameter (default is 1.0).\n",
    "\n",
    "    Returns:\n",
    "    defaultdict: Smoothed n-gram model.\n",
    "    \"\"\"\n",
    "    smoothed_model = defaultdict(Counter)\n",
    "    for prefix, char_counts in model.items():\n",
    "        total_count = sum(char_counts.values()) + alpha * vocabulary_size\n",
    "        for char in char_counts:\n",
    "            smoothed_model[prefix][char] = (char_counts[char] + alpha) / total_count\n",
    "        for char in range(vocabulary_size):\n",
    "            if char not in char_counts:\n",
    "                smoothed_model[prefix][char] = alpha / total_count\n",
    "    return smoothed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, n, start_text, length=100):\n",
    "    \"\"\"\n",
    "    Generate text using the n-gram model.\n",
    "\n",
    "    Parameters:\n",
    "    model (dict): Trained n-gram model\n",
    "    n (int): Size of the n-grams\n",
    "    start_text (str): Initial text to start generation\n",
    "    length (int): Number of characters to generate\n",
    "\n",
    "    Returns:\n",
    "    str: Generated text\n",
    "    \"\"\"\n",
    "    # Initialize with start text\n",
    "    current_text = list(start_text)\n",
    "\n",
    "    # Generate characters\n",
    "    for _ in range(length):\n",
    "        # Get the current context\n",
    "        context = tuple(current_text[-(n-1):]) if len(current_text) >= n-1 else tuple('#' * (n-1 - len(current_text)) + ''.join(current_text))\n",
    "\n",
    "        # If context not in model, break\n",
    "        if context not in model:\n",
    "            break\n",
    "\n",
    "        # Get probability distribution for next character\n",
    "        char_dist = model[context]\n",
    "\n",
    "        # Sample next character\n",
    "        chars, probs = zip(*char_dist.items())\n",
    "        next_char = random.choices(chars, weights=probs)[0]\n",
    "\n",
    "        # Append to generated text\n",
    "        current_text.append(next_char)\n",
    "\n",
    "    return ''.join(current_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: are t the F1\n"
     ]
    }
   ],
   "source": [
    "# Sample text\n",
    "text = \"Aryton Senna was the greatest racer the world could ever see in F1, Ken Miles was the overpowered man for sure\"\n",
    "\n",
    "# Build a bigram model\n",
    "bigram_model = build_ngram_model(text, 2)\n",
    "\n",
    "# Generate text\n",
    "generated = generate_text(bigram_model, 2, \"ar\", 10)\n",
    "print(f\"Generated text: {generated}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity(model, n, test_text):\n",
    "    \"\"\"\n",
    "    Calculate perplexity of the model on test text.\n",
    "\n",
    "    Parameters:\n",
    "    model (dict): Trained n-gram model\n",
    "    n (int): Size of the n-grams\n",
    "    test_text (str): Text to evaluate on\n",
    "\n",
    "    Returns:\n",
    "    float: Perplexity score\n",
    "    \"\"\"\n",
    "    ngrams = generate_ngrams(test_text, n)\n",
    "    log_prob = 0\n",
    "    total_ngrams = len(ngrams)\n",
    "\n",
    "    for ngram in ngrams:\n",
    "        context = ngram[:-1]\n",
    "        char = ngram[-1]\n",
    "\n",
    "        if context in model and char in model[context]:\n",
    "            prob = model[context][char]\n",
    "            log_prob += -1 * math.log2(prob)\n",
    "        else:\n",
    "            return float('inf')  # Return infinity for unseen n-grams\n",
    "\n",
    "    return 2 ** (log_prob / total_ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's create a more substantial training corpus\n",
    "training_corpus = \"\"\"\n",
    "The quick brown fox jumps over the lazy dog.\n",
    "She sells seashells by the seashore.\n",
    "How much wood would a woodchuck chuck if a woodchuck could chuck wood?\n",
    "To be or not to be, that is the question.\n",
    "All that glitters is not gold.\n",
    "A journey of a thousand miles begins with a single step.\n",
    "Actions speak louder than words.\n",
    "Beauty is in the eye of the beholder.\n",
    "Every cloud has a silver lining.\n",
    "Fortune favors the bold and brave.\n",
    "Life is like a box of chocolates.\n",
    "The early bird catches the worm.\n",
    "Where there's smoke, there's fire.\n",
    "Time heals all wounds and teaches all things.\n",
    "Knowledge is power, and power corrupts.\n",
    "Practice makes perfect, but nobody's perfect.\n",
    "The pen is mightier than the sword.\n",
    "When in Rome, do as the Romans do.\n",
    "A picture is worth a thousand words.\n",
    "Better late than never, but never late is better.\n",
    "Experience is the best teacher of all things.\n",
    "Laughter is the best medicine for the soul.\n",
    "Music soothes the savage beast within us.\n",
    "Nothing ventured, nothing gained in life.\n",
    "The grass is always greener on the other side.\n",
    "\"\"\"\n",
    "\n",
    "# Clean the corpus\n",
    "training_corpus = ''.join(c.lower() for c in training_corpus if c.isalnum() or c.isspace())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
